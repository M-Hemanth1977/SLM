{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6pFdYuPZ4q3S",
      "metadata": {
        "id": "6pFdYuPZ4q3S"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eada4943",
      "metadata": {
        "id": "eada4943"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "import torch\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk import sent_tokenize,word_tokenize\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#downloading nltk data\n",
        "try:\n",
        "    nltk.download('punkt')\n",
        "    nltk.download('stopwords')\n",
        "    nltk.download('punkt_tab')\n",
        "except:\n",
        "    pass\n",
        "\n",
        "#setting device\n",
        "if torch.cuda.is_available():\n",
        "    dev='cuda'\n",
        "else:\n",
        "    dev='cpu'\n",
        "\n",
        "device=torch.device(device=dev)\n",
        "print(f\"The code is using device:{device}\")\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca324c50",
      "metadata": {
        "id": "ca324c50"
      },
      "outputs": [],
      "source": [
        "# Data loading and pretraining\n",
        "\n",
        "with open(file=r\"/content/drive/MyDrive/wiki.train.tokens\",mode=\"r\",encoding='utf-8') as f:\n",
        "\n",
        "    wiki_text=f.read()\n",
        "    sentences=sent_tokenize(text=wiki_text)[:20000]\n",
        "\n",
        "    pre_training_text=[]\n",
        "\n",
        "    for i in range(0,len(sentences),3):\n",
        "        pre_training_text.append(' '.join(sentences[i:i+3]))\n",
        "\n",
        "\n",
        "print(pre_training_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c53ac0c",
      "metadata": {
        "id": "8c53ac0c"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import GPT2Tokenizer\n",
        "\n",
        "tokenizer=GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.pad_token=tokenizer.eos_token\n",
        "print(\"Tokenizer initiated\")\n",
        "\n",
        "embedding_model=SentenceTransformer(model_name_or_path='sentence-transformers/all-MiniLM-L6-v2')\n",
        "print(\"Embedding model initiated\")\n",
        "\n",
        "print(tokenizer)\n",
        "print(embedding_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ARvqp25rW9dX",
      "metadata": {
        "id": "ARvqp25rW9dX"
      },
      "outputs": [],
      "source": [
        "file_path =r'/content/drive/MyDrive/extracted_text.txt'\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as f:\n",
        "    file_text = f.read()[:200000]\n",
        "print(\"file document loaded successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nS5s9A0RZTtD",
      "metadata": {
        "id": "nS5s9A0RZTtD"
      },
      "outputs": [],
      "source": [
        "# file_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "t_IgjnIyXuzJ",
      "metadata": {
        "id": "t_IgjnIyXuzJ"
      },
      "outputs": [],
      "source": [
        "# file_text='. '.join(file_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0012afb5",
      "metadata": {
        "id": "0012afb5"
      },
      "outputs": [],
      "source": [
        "# Process file document for fine-tuning\n",
        "file_sentences = sent_tokenize(file_text)\n",
        "\n",
        "finetune_data=[]\n",
        "\n",
        "for sent in file_sentences:\n",
        "    if len(sent)>20:\n",
        "        finetune_data.append(sent.strip())\n",
        "\n",
        "print(f\"Processed {len(finetune_data)} fine-tuning samples from file document\")\n",
        "\n",
        "# Create document chunks for RAG retrieval\n",
        "document_chunks = []\n",
        "paragraphs = file_text.split('\\n\\n')\n",
        "for para in paragraphs:\n",
        "    para = para.strip()\n",
        "    if len(para) > 50:  # Only meaningful paragraphs\n",
        "        # Split long paragraphs into smaller chunks\n",
        "        if len(para) > 300:\n",
        "            sentences = sent_tokenize(para)\n",
        "            for i in range(0, len(sentences), 2):\n",
        "                chunk = ' '.join(sentences[i:i+2])\n",
        "                if len(chunk) > 50:\n",
        "                    document_chunks.append(chunk)\n",
        "        else:\n",
        "            document_chunks.append(para)\n",
        "\n",
        "print(f\"Created {len(document_chunks)} retrieval chunks\")\n",
        "print(\"Data loading complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58bc627a",
      "metadata": {
        "id": "58bc627a"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import re\n",
        "import os\n",
        "from collections import Counter\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VSn8ABD82DWw",
      "metadata": {
        "id": "VSn8ABD82DWw"
      },
      "outputs": [],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd317a8f",
      "metadata": {
        "id": "dd317a8f"
      },
      "outputs": [],
      "source": [
        "# Instaling required graph libraries\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "from torch_geometric.nn import GCNConv, GATv2Conv, global_mean_pool\n",
        "from torch_geometric.data import Data, Batch\n",
        "print(\"PyTorch Geometric already installed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54f66d65",
      "metadata": {
        "id": "54f66d65"
      },
      "outputs": [],
      "source": [
        "class CGTConfig:\n",
        "    \"\"\"Configuration for Contextual Graph Transformer\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.vocab_size = 50257\n",
        "        self.hidden_dim = 384\n",
        "        self.gnn_layers = 3\n",
        "        self.transformer_layers = 4\n",
        "        self.num_heads = 8\n",
        "        self.gnn_type = 'gat'  # 'gcn' or 'gat'\n",
        "        self.dropout = 0.1\n",
        "        self.max_seq_len = 512\n",
        "\n",
        "cgt_config=CGTConfig()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47b5c4c3",
      "metadata": {
        "id": "47b5c4c3"
      },
      "outputs": [],
      "source": [
        "class ContextualGraphTransformer(nn.Module):\n",
        "    \"\"\"Hybrid GNN + Transformer model for contextual understanding\"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # Input token Embeddings\n",
        "        self.embedding = nn.Embedding(config.vocab_size, config.hidden_dim)\n",
        "        self.pos_embedding = nn.Embedding(config.max_seq_len, config.hidden_dim)\n",
        "\n",
        "        # GNN Layers for capturing local context\n",
        "        self.gnn_layers = nn.ModuleList()\n",
        "        for i in range(config.gnn_layers):\n",
        "            if config.gnn_type == 'gat':\n",
        "                self.gnn_layers.append(GATv2Conv(config.hidden_dim, config.hidden_dim))\n",
        "            else:\n",
        "                self.gnn_layers.append(GCNConv(config.hidden_dim, config.hidden_dim))\n",
        "\n",
        "        # Layer Normalization after GNN\n",
        "        self.gnn_ln = nn.LayerNorm(config.hidden_dim)\n",
        "\n",
        "        # Transformer Layers for capturing global context\n",
        "        transformer_encoder_layer = nn.TransformerEncoderLayer(\n",
        "            config.hidden_dim,\n",
        "            nhead=8,\n",
        "            dim_feedforward=4 * config.hidden_dim,\n",
        "            dropout=config.dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(transformer_encoder_layer, num_layers=config.transformer_layers)\n",
        "\n",
        "        # Context Fusion Layer (Multi-Head Attention)\n",
        "        self.fusion_attention = nn.MultiheadAttention(\n",
        "            embed_dim=config.hidden_dim,\n",
        "            num_heads=8,\n",
        "            dropout=config.dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Output Layers\n",
        "        self.ln_f = nn.LayerNorm(config.hidden_dim)\n",
        "        # Enhanced output head: Two-layer FFN\n",
        "        self.head_ffn = nn.Sequential(\n",
        "            nn.Linear(config.hidden_dim, config.hidden_dim * 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(config.dropout),\n",
        "            nn.Linear(config.hidden_dim * 2, config.vocab_size)\n",
        "        )\n",
        "\n",
        "        # Calculate total parameters\n",
        "        total_params = sum(p.numel() for p in self.parameters()) / 1e6\n",
        "        print(f\"CGT Model: {config.gnn_layers} GNN + {config.transformer_layers} Transformer layers outline ready\")\n",
        "        print(f\"Total parameters: {total_params:.1f}M\")\n",
        "\n",
        "    def create_graph(self, input_ids):\n",
        "        batch_size, seq_len = input_ids.shape\n",
        "        graphs = []\n",
        "\n",
        "        for b in range(batch_size):\n",
        "            x = self.embedding(input_ids[b]) + self.pos_embedding(torch.arange(seq_len, device=input_ids.device))\n",
        "            edge_index = []\n",
        "\n",
        "            # Adjacent nodes\n",
        "            for i in range(seq_len - 1):\n",
        "                edge_index.append([i, i + 1])\n",
        "                edge_index.append([i + 1, i])\n",
        "\n",
        "            # Skip connections\n",
        "            for i in range(seq_len - 2):\n",
        "                edge_index.append([i, i + 2])\n",
        "                edge_index.append([i + 2, i])\n",
        "\n",
        "            if edge_index:\n",
        "                edge_index = torch.tensor(edge_index, dtype=torch.long, device=input_ids.device).t().contiguous()\n",
        "            else:\n",
        "                edge_index = torch.empty((2, 0), device=input_ids.device, dtype=torch.long)\n",
        "\n",
        "            graphs.append(Data(x, edge_index))\n",
        "\n",
        "        return Batch.from_data_list(graphs)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        graph_batch = self.create_graph(input_ids)\n",
        "        x = graph_batch.x\n",
        "\n",
        "        # GNN processing with dropout\n",
        "        for gnn_layer in self.gnn_layers:\n",
        "            x = F.dropout(x, p=self.config.dropout, training=self.training)\n",
        "            x = F.relu(gnn_layer(x, graph_batch.edge_index))\n",
        "\n",
        "        # Normalize GNN output\n",
        "        x = self.gnn_ln(x)\n",
        "\n",
        "        # Reshape for Transformer\n",
        "        batch_size, seq_len = input_ids.shape\n",
        "        x_gnn = x.view(batch_size, seq_len, -1)\n",
        "\n",
        "        # Transformer processing\n",
        "        if attention_mask is not None:\n",
        "            attention_mask = attention_mask.bool()\n",
        "            attention_mask = ~attention_mask  # Invert for transformer\n",
        "        x_transformer = self.transformer(x_gnn, src_key_padding_mask=attention_mask)\n",
        "\n",
        "        # Context fusion: Combine GNN and Transformer outputs\n",
        "        x_fused, _ = self.fusion_attention(x_transformer, x_gnn, x_gnn)\n",
        "\n",
        "        # Residual connection\n",
        "        x = x_fused + x_transformer\n",
        "\n",
        "        # Final processing\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.head_ffn(x)\n",
        "\n",
        "        return logits\n",
        "\n",
        "model = ContextualGraphTransformer(config=cgt_config).to(device)\n",
        "print(f\"NEW CGT Model initialized with {sum(p.numel() for p in model.parameters())/1e6:.1f}M parameters\")\n",
        "print(\"Hybrid GNN + Transformer architecture ready!\")\n",
        "print(f\"Architecture: {cgt_config.gnn_layers} GNN layers + {cgt_config.transformer_layers} Transformer layers\")\n",
        "print(f\"Model type: {type(model).__name__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00a4a84c",
      "metadata": {
        "id": "00a4a84c"
      },
      "outputs": [],
      "source": [
        "len(finetune_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e07efb3",
      "metadata": {
        "id": "0e07efb3"
      },
      "outputs": [],
      "source": [
        "def train_model(model,data,tokenizer,epochs=None,learning_rate=None,stage=None):\n",
        "    \"\"\" Training function for both pretraining and fine-tuning\"\"\"\n",
        "\n",
        "    # Optimizer and loss function\n",
        "    optimizer=torch.optim.AdamW(model.parameters(),lr=learning_rate)\n",
        "    loss_function=nn.CrossEntropyLoss()\n",
        "\n",
        "    print(f\"Starting {stage} for {epochs} epochs...\")\n",
        "\n",
        "    # Setting model in training mode\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss=0\n",
        "        batch_count=0\n",
        "\n",
        "        batch_size=16\n",
        "\n",
        "        for i in range(0,len(data),batch_size):\n",
        "\n",
        "            batched_data=data[i:i+batch_size]\n",
        "\n",
        "            inputs=tokenizer(batched_data,\n",
        "                      padding=True,\n",
        "                      truncation=True,\n",
        "                      max_length=128,\n",
        "                      return_tensors='pt'\n",
        "                      )\n",
        "\n",
        "            input_ids=inputs['input_ids'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids)\n",
        "\n",
        "            # Calculate loss (next token prediction)\n",
        "            shift_logits = outputs[..., :-1, :].contiguous()\n",
        "            shift_labels = input_ids[..., 1:].contiguous()\n",
        "\n",
        "            loss = loss_function(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            batch_count += 1\n",
        "\n",
        "            if batch_count % 10 == 0:\n",
        "                print(f\"Epoch {epoch+1}/{epochs}, Batch {batch_count}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "        avg_loss = total_loss / batch_count\n",
        "        print(f\"Epoch {epoch+1} completed, Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    print(f\" Training for {stage} completed successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d637a87",
      "metadata": {
        "id": "1d637a87"
      },
      "outputs": [],
      "source": [
        "print(\" Starting Pre_training phase\")\n",
        "train_model(model,pre_training_text,tokenizer,epochs=5,learning_rate=1e-5,stage=\"Pre_training\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8de9a09a",
      "metadata": {
        "id": "8de9a09a"
      },
      "outputs": [],
      "source": [
        "torch.save(model,r\"/content/pre_training_model.pt\")\n",
        "print(\"Pre_trained model saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43e2d4c9",
      "metadata": {
        "id": "43e2d4c9"
      },
      "outputs": [],
      "source": [
        "print(\" Starting Fine_tuning phase\")\n",
        "train_model(model,finetune_data,tokenizer,epochs=20,learning_rate=5e-5,stage=\"Fine_Tuning\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "560f3032",
      "metadata": {
        "id": "560f3032"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), r\"/content/fine_tuned_model.pt\")\n",
        "print(\"Fine-tuned model saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fff3e7b9",
      "metadata": {
        "id": "fff3e7b9"
      },
      "outputs": [],
      "source": [
        "class CGTBasedRAGSystem:\n",
        "\n",
        "    def __init__(self,cgt_model, tokenizer, embedding_model, document_chunks):\n",
        "\n",
        "        self.cgt_model=cgt_model\n",
        "        self.tokenizer=tokenizer\n",
        "        self.embedding_model=embedding_model\n",
        "        self.document_chunks=document_chunks\n",
        "\n",
        "        print(\"Computing embeddings for chunks\")\n",
        "        self.chunk_embeddings=self.embedding_model.encode(document_chunks)\n",
        "        print(f\"All embeddings for {len(document_chunks)} chunks are created Succesfully\")\n",
        "\n",
        "\n",
        "    def retrieve_relavent_chunks(self,query,top_k=None):\n",
        "\n",
        "        query_embeddings=self.embedding_model.encode([query])\n",
        "\n",
        "        similarity=cosine_similarity(query_embeddings,self.chunk_embeddings)\n",
        "\n",
        "        top_indices = np.argsort(similarity[0])[-top_k:][::-1]\n",
        "\n",
        "        relavent_chunks=[]\n",
        "\n",
        "        for i in top_indices:\n",
        "            relavent_chunks.append(self.document_chunks[i])\n",
        "\n",
        "        return relavent_chunks,len(relavent_chunks)\n",
        "\n",
        "\n",
        "    def clean_response(self, response):\n",
        "        \"\"\"Clean and format the response\"\"\"\n",
        "\n",
        "        if not response:\n",
        "            return \"\"\n",
        "\n",
        "        # Remove extra whitespace\n",
        "        response = ' '.join(response.split())\n",
        "\n",
        "        # Ensure proper punctuation\n",
        "        if response and not response.endswith(('.', '!', '?')):\n",
        "            response += '.'\n",
        "\n",
        "        return response\n",
        "\n",
        "\n",
        "    def generate_with_cgt(self,query,relavent_context):\n",
        "\n",
        "        related_chunks=' '.join(relavent_context)\n",
        "\n",
        "        prompt = f\"Context: {related_chunks[:500]}\\n\\nQuestion: {query}\\nAnswer:\"\n",
        "\n",
        "        inputs=self.tokenizer(prompt,padding=True,truncation=True,max_length=200,return_tensors='pt')\n",
        "\n",
        "        input_ids = inputs['input_ids'].to(device)\n",
        "        attention_mask = inputs['attention_mask'].to(device)\n",
        "\n",
        "        print(input_ids)\n",
        "        print(attention_mask)\n",
        "\n",
        "        # Generate using CGT model\n",
        "        self.cgt_model.eval()\n",
        "        with torch.no_grad():\n",
        "            generated_tokens = []\n",
        "            current_input = input_ids\n",
        "            current_mask = attention_mask\n",
        "\n",
        "            # Generate tokens one by one\n",
        "            for step in range(50):  # Generate up to 50 tokens\n",
        "                # Forward pass through CGT (GNN + Transformer)\n",
        "                outputs = self.cgt_model(current_input, attention_mask=current_mask)\n",
        "\n",
        "                # print(f\"for step: {step} the outputs: {outputs}\")\n",
        "\n",
        "                # Get logits for the last token\n",
        "                logits = outputs[:, -1, :]\n",
        "\n",
        "                # Apply temperature for controlled generation\n",
        "                temperature = 0.7\n",
        "                logits = logits / temperature\n",
        "\n",
        "                # Use top-k sampling\n",
        "                top_k = 40\n",
        "                top_k_logits, top_k_indices = torch.topk(logits, k=top_k)\n",
        "                probabilities = F.softmax(top_k_logits, dim=-1)\n",
        "\n",
        "                # Sample from top-k distribution\n",
        "                next_token_idx = torch.multinomial(probabilities, 1)\n",
        "                next_token_id = top_k_indices.gather(-1, next_token_idx)\n",
        "\n",
        "                # Stop on EOS token\n",
        "                if next_token_id.item() == self.tokenizer.eos_token_id:\n",
        "                    break\n",
        "\n",
        "                generated_tokens.append(next_token_id.item())\n",
        "\n",
        "                # Update input for next iteration\n",
        "                current_input = torch.cat([current_input, next_token_id], dim=-1)\n",
        "                new_mask = torch.ones((1, 1), device=device)\n",
        "                current_mask = torch.cat([current_mask, new_mask], dim=-1)\n",
        "\n",
        "                # Stop at sentence boundaries for natural responses\n",
        "                if len(generated_tokens) > 20:\n",
        "                    decoded_so_far = self.tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
        "                    if decoded_so_far.endswith('.') and step > 25:\n",
        "                        break\n",
        "\n",
        "            # Decode generated tokens\n",
        "            if generated_tokens:\n",
        "                generated_text = self.tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
        "                generated_text = generated_text.strip()\n",
        "\n",
        "                # Clean response\n",
        "                if generated_text and len(generated_text.split()) >= 5:\n",
        "                    return self.clean_response(generated_text)\n",
        "\n",
        "        return self.intelligent_context_extraction(query, relavent_context)\n",
        "\n",
        "\n",
        "    def intelligent_context_extraction(self, query, context_chunks):\n",
        "        \"\"\"Extract relevant information when model generation fails\"\"\"\n",
        "\n",
        "        # Combine all context\n",
        "        full_context = \" \".join(context_chunks)\n",
        "\n",
        "        # Split into sentences\n",
        "        sentences = [s.strip() for s in full_context.split('.') if len(s.strip()) > 15]\n",
        "\n",
        "        # Extract query keywords\n",
        "        query_lower = query.lower()\n",
        "        query_keywords = set([\n",
        "            word.strip('.,!?()[]{}\";:')\n",
        "            for word in query_lower.split()\n",
        "            if len(word) > 2 and word not in ['what', 'is', 'the', 'how', 'does', 'are', 'for', 'and', 'or', 'but']\n",
        "        ])\n",
        "\n",
        "        # Score sentences by relevance\n",
        "        scored_sentences = []\n",
        "        for sentence in sentences:\n",
        "            sentence_lower = sentence.lower()\n",
        "            sentence_words = set(word.strip('.,!?()[]{}\";:') for word in sentence_lower.split())\n",
        "\n",
        "            # Calculate relevance score\n",
        "            keyword_overlap = len(query_keywords.intersection(sentence_words))\n",
        "            if keyword_overlap > 0:\n",
        "                scored_sentences.append((sentence, keyword_overlap))\n",
        "\n",
        "        # Return best matching sentence\n",
        "        if scored_sentences:\n",
        "            scored_sentences.sort(key=lambda x: x[1], reverse=True)\n",
        "            best_sentence = scored_sentences[0][0].strip()\n",
        "\n",
        "            if best_sentence:\n",
        "                # Ensure proper formatting\n",
        "                best_sentence = best_sentence[0].upper() + best_sentence[1:]\n",
        "                if not best_sentence.endswith(('.', '!', '?')):\n",
        "                    best_sentence += '.'\n",
        "                return best_sentence\n",
        "\n",
        "        return \"Information not found in the provided documentation.\"\n",
        "\n",
        "\n",
        "    def question_answering(self,query):\n",
        "\n",
        "        relavent_context,num_chunks=self.retrieve_relavent_chunks(query,top_k=3)\n",
        "\n",
        "        answer=self.generate_with_cgt(query,relavent_context)\n",
        "\n",
        "        formatted_response = f\"\"\"Question: {query}\n",
        "        Answer: {answer}\"\"\"\n",
        "\n",
        "        return formatted_response\n",
        "\n",
        "# Initialize CGT-based RAG system (overriding previous)\n",
        "print(\"Initializing CGT-based RAG system...\")\n",
        "cgt_rag_system = CGTBasedRAGSystem(model, tokenizer, embedding_model, document_chunks)\n",
        "print(\"CGT-based RAG system ready!\")\n",
        "print(\"Using hybrid GNN + Transformer architecture\")\n",
        "print(\"Graph neural networks for local context\")\n",
        "print(\"Transformers for global dependencies\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "388eec64",
      "metadata": {
        "id": "388eec64"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "print(\"TESTING CGT-BASED RAG SYSTEM (GNN + TRANSFORMER)\")\n",
        "\n",
        "test_questions = [\n",
        "    \"What Federated Learning does?\"\n",
        "]\n",
        "\n",
        "print(f\"Model Architecture: {type(model).__name__}\")\n",
        "print(f\"Testing with {len(test_questions)} questions...\")\n",
        "\n",
        "for i, question in enumerate(test_questions, 1):\n",
        "\n",
        "    start_time = time.time()\n",
        "    response = cgt_rag_system.question_answering(question)\n",
        "    generation_time = time.time() - start_time\n",
        "\n",
        "    print(response)\n",
        "    print(f\"\\nGeneration time: {generation_time:.2f} seconds\")\n",
        "    print(f\"Architecture: GNN + Transformer hybrid processing\")\n",
        "\n",
        "\n",
        "print(\"CGT RAG SYSTEM TEST COMPLETE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vABdbsyWk452",
      "metadata": {
        "id": "vABdbsyWk452"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}