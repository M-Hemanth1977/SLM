# -*- coding: utf-8 -*-
"""q&a_extraction_for_slm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h3rTGYpE9MKebyitGLM2vvLhVutyRytP
"""

!pip install pyPDF2

from google.colab import drive
drive.mount('/content/drive')

from PyPDF2 import PdfReader

reader=PdfReader(stream=r"/content/drive/MyDrive/Fed_Meta_Allign.pdf")

text=""

for page in reader.pages:

  text+=page.extract_text()

from langchain_text_splitters import RecursiveCharacterTextSplitter

splitter=RecursiveCharacterTextSplitter(separators=["\n\n","\n"],chunk_size=500,chunk_overlap=50)

splitted=splitter.split_text(text=text)

!pip install langchain_google_genai

import google.generativeai as genai
from google.colab import userdata

# Configure Gemini
genai.configure(api_key=userdata.get('google'))
model = genai.GenerativeModel('models/gemma-3-27b-it')

def generate_qa_pairs(text):
    prompt = f"""
    You are a Technical AI Assistant specialized in Federated Learning and TinyML.
    Based on the text below, generate exactly 3 Question and Answer pairs about Fed-Meta-Align.

    TEXT: {text}

    Generate in this format:
    Q1: [Specific technical question]
    A1: [Brief 2-3 line answer]

    Q2: [Specific technical question]
    A2: [Brief 2-3 line answer]

    Q3: [Specific technical question]
    A3: [Brief 2-3 line answer]
    """

    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"Error: {str(e)}"

# Process batches
all_outputs = []
for index, sentence in enumerate(splitted):
    print(f"Processing Batch-{index+1}/{len(splitted)}...")

    try:
        if sentence.strip() and len(sentence) > 50:  # Only process meaningful text
            response = generate_qa_pairs(sentence)
            all_outputs.append(response)
            print(f"Batch-{index+1} processing done.")
            print(f"Preview: {response[:100]}...")
        else:
            print(f"Batch-{index+1} skipped - too short")
            all_outputs.append("")

    except Exception as e:
        print(f"Batch-{index+1} processing failed: {e}")
        all_outputs.append("")

import re

qa_pairs = []

pattern = re.compile(r"(Q\d*:\s*(.*?))\n(A\d*:\s*(.*?))(?=\nQ|\Z)", re.DOTALL)

for index,text in enumerate(all_outputs):
    matches = pattern.findall(text)
    for q_full, q, a_full, a in matches:
        qa_pairs.append((q_full.strip(), a_full.strip()))

with open("filtered_qna.txt", "w") as f:
    for q, a in qa_pairs:
        f.write(f"{q}\n{a}\n\n")

print(f"Extracted {len(qa_pairs)} Q&A pairs and saved to 'filtered_qna.txt'")



